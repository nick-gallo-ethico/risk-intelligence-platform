---
phase: 05-ai-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - apps/backend/package.json
  - apps/backend/src/modules/ai/ai.module.ts
  - apps/backend/src/modules/ai/services/ai-client.service.ts
  - apps/backend/src/modules/ai/dto/chat-message.dto.ts
  - apps/backend/src/modules/ai/dto/index.ts
  - apps/backend/src/modules/ai/index.ts
  - apps/backend/src/app.module.ts
autonomous: true
user_setup:
  - service: anthropic
    why: "Claude API for AI features"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys -> Create key"

must_haves:
  truths:
    - "AI client can call Claude API with proper authentication"
    - "AI calls are tenant-isolated via organizationId parameter"
    - "Streaming responses work with async iterators"
    - "API errors are caught and wrapped in application errors"
  artifacts:
    - path: "apps/backend/src/modules/ai/ai.module.ts"
      provides: "AiModule with AiClientService"
      exports: ["AiModule"]
    - path: "apps/backend/src/modules/ai/services/ai-client.service.ts"
      provides: "Claude API wrapper with streaming"
      exports: ["AiClientService"]
      min_lines: 80
  key_links:
    - from: "apps/backend/src/modules/ai/services/ai-client.service.ts"
      to: "@anthropic-ai/sdk"
      via: "import Anthropic"
      pattern: "import.*Anthropic.*from.*@anthropic-ai/sdk"
    - from: "apps/backend/src/app.module.ts"
      to: "AiModule"
      via: "imports array"
      pattern: "AiModule"
---

<objective>
Create the foundational Claude API client integration using @anthropic-ai/sdk. This establishes the core AI service that all other AI features build upon.

Purpose: Every AI feature (note cleanup, summaries, categorization, agent chat) needs a properly configured Claude client with streaming support and tenant isolation.

Output: AiModule with AiClientService that wraps Claude SDK with NestJS patterns.
</objective>

<execution_context>
@C:\Users\cu0718\.claude\get-shit-done\workflows\execute-plan.md
@C:\Users\cu0718\.claude\get-shit-done\templates\summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-ai-infrastructure/05-RESEARCH.md

# Prior phase context
@.planning/phases/01-foundation-infrastructure/01-02-SUMMARY.md (AI queue infrastructure with BullMQ)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install @anthropic-ai/sdk and create AiModule</name>
  <files>
    apps/backend/package.json
    apps/backend/src/modules/ai/ai.module.ts
    apps/backend/src/modules/ai/index.ts
    apps/backend/src/app.module.ts
  </files>
  <action>
Install the Anthropic SDK:
```bash
cd apps/backend && npm install @anthropic-ai/sdk
```

Create the AI module structure:

1. Create `apps/backend/src/modules/ai/ai.module.ts`:
```typescript
import { Module } from '@nestjs/common';
import { ConfigModule } from '@nestjs/config';
import { AiClientService } from './services/ai-client.service';

@Module({
  imports: [ConfigModule],
  providers: [AiClientService],
  exports: [AiClientService],
})
export class AiModule {}
```

2. Create `apps/backend/src/modules/ai/index.ts` barrel export:
```typescript
export * from './ai.module';
export * from './services/ai-client.service';
export * from './dto';
```

3. Add AiModule to `apps/backend/src/app.module.ts` imports array after RiusModule.

Add ANTHROPIC_API_KEY to .env.example if not present.
  </action>
  <verify>
`npm run build` in apps/backend succeeds without errors.
Package @anthropic-ai/sdk appears in package.json dependencies.
  </verify>
  <done>
AiModule exists and is registered in AppModule.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create AiClientService with streaming support</name>
  <files>
    apps/backend/src/modules/ai/services/ai-client.service.ts
    apps/backend/src/modules/ai/dto/chat-message.dto.ts
    apps/backend/src/modules/ai/dto/index.ts
  </files>
  <action>
Create the core AI client service:

1. Create `apps/backend/src/modules/ai/dto/chat-message.dto.ts`:
```typescript
import { IsString, IsOptional, IsEnum, IsArray, IsObject, MaxLength } from 'class-validator';

export enum MessageRole {
  USER = 'user',
  ASSISTANT = 'assistant',
}

export class ChatMessageDto {
  @IsEnum(MessageRole)
  role: MessageRole;

  @IsString()
  @MaxLength(100000) // ~25K tokens worth of text
  content: string;
}

export class CreateChatDto {
  @IsString()
  organizationId: string;

  @IsString()
  @IsOptional()
  entityType?: string;

  @IsString()
  @IsOptional()
  entityId?: string;

  @IsString()
  @MaxLength(100000)
  message: string;

  @IsArray()
  @IsOptional()
  history?: ChatMessageDto[];

  @IsString()
  @IsOptional()
  systemPrompt?: string;
}

export interface StreamEvent {
  type: 'text_delta' | 'tool_use_start' | 'tool_input_delta' | 'tool_result' | 'message_complete' | 'error';
  text?: string;
  toolId?: string;
  toolName?: string;
  input?: unknown;
  error?: string;
}

export interface AiResponse {
  content: string;
  inputTokens: number;
  outputTokens: number;
  stopReason: string;
}
```

2. Create `apps/backend/src/modules/ai/dto/index.ts`:
```typescript
export * from './chat-message.dto';
```

3. Create `apps/backend/src/modules/ai/services/ai-client.service.ts`:
```typescript
import { Injectable, Logger, OnModuleInit } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import Anthropic from '@anthropic-ai/sdk';
import { CreateChatDto, StreamEvent, AiResponse, MessageRole } from '../dto/chat-message.dto';

@Injectable()
export class AiClientService implements OnModuleInit {
  private readonly logger = new Logger(AiClientService.name);
  private client: Anthropic;
  private readonly activeStreams = new Map<string, AbortController>();

  // Default model - claude-sonnet-4-5 for good balance of speed/quality
  private readonly defaultModel = 'claude-sonnet-4-5';
  private readonly maxTokens = 4096;

  constructor(private readonly configService: ConfigService) {}

  onModuleInit() {
    const apiKey = this.configService.get<string>('ANTHROPIC_API_KEY');
    if (!apiKey) {
      this.logger.warn('ANTHROPIC_API_KEY not set - AI features will be disabled');
      return;
    }

    this.client = new Anthropic({ apiKey });
    this.logger.log('Anthropic client initialized');
  }

  isConfigured(): boolean {
    return !!this.client;
  }

  /**
   * Create a chat completion (non-streaming)
   */
  async createChat(params: CreateChatDto): Promise<AiResponse> {
    this.ensureConfigured();

    const messages = this.buildMessages(params);

    const response = await this.client.messages.create({
      model: this.defaultModel,
      max_tokens: this.maxTokens,
      system: params.systemPrompt || this.getDefaultSystemPrompt(),
      messages,
    });

    const textContent = response.content
      .filter(block => block.type === 'text')
      .map(block => (block as { type: 'text'; text: string }).text)
      .join('');

    return {
      content: textContent,
      inputTokens: response.usage.input_tokens,
      outputTokens: response.usage.output_tokens,
      stopReason: response.stop_reason || 'end_turn',
    };
  }

  /**
   * Stream a chat completion
   * @param streamId Unique ID to track this stream for abort support
   */
  async *streamChat(
    params: CreateChatDto,
    streamId: string,
  ): AsyncGenerator<StreamEvent> {
    this.ensureConfigured();

    const messages = this.buildMessages(params);
    const abortController = new AbortController();
    this.activeStreams.set(streamId, abortController);

    try {
      const stream = this.client.messages.stream({
        model: this.defaultModel,
        max_tokens: this.maxTokens,
        system: params.systemPrompt || this.getDefaultSystemPrompt(),
        messages,
      }, {
        signal: abortController.signal,
      });

      for await (const event of stream) {
        if (event.type === 'content_block_delta') {
          const delta = event.delta as { type: string; text?: string };
          if (delta.type === 'text_delta' && delta.text) {
            yield { type: 'text_delta', text: delta.text };
          }
        } else if (event.type === 'message_stop') {
          yield { type: 'message_complete' };
        }
      }
    } catch (error) {
      if (error.name === 'AbortError') {
        this.logger.debug(`Stream ${streamId} aborted`);
        return;
      }

      this.logger.error(`Stream error: ${error.message}`, error.stack);
      yield { type: 'error', error: error.message };
    } finally {
      this.activeStreams.delete(streamId);
    }
  }

  /**
   * Abort an active stream
   */
  abortStream(streamId: string): boolean {
    const controller = this.activeStreams.get(streamId);
    if (controller) {
      controller.abort();
      this.activeStreams.delete(streamId);
      return true;
    }
    return false;
  }

  /**
   * Estimate token count for text (rough estimation: ~4 chars per token)
   */
  estimateTokens(text: string): number {
    return Math.ceil(text.length / 4);
  }

  private ensureConfigured(): void {
    if (!this.client) {
      throw new Error('AI service not configured - ANTHROPIC_API_KEY not set');
    }
  }

  private buildMessages(params: CreateChatDto): Array<{ role: 'user' | 'assistant'; content: string }> {
    const messages: Array<{ role: 'user' | 'assistant'; content: string }> = [];

    // Add history if provided
    if (params.history) {
      for (const msg of params.history) {
        messages.push({
          role: msg.role === MessageRole.USER ? 'user' : 'assistant',
          content: msg.content,
        });
      }
    }

    // Add current message
    messages.push({
      role: 'user',
      content: params.message,
    });

    return messages;
  }

  private getDefaultSystemPrompt(): string {
    return `You are an AI assistant for a compliance and risk management platform. You help users with:
- Summarizing cases and investigations
- Cleaning up and formatting notes
- Categorizing reports
- Answering questions about compliance matters
- Generating risk assessments

Always be professional, accurate, and thorough. When dealing with sensitive information, maintain confidentiality and follow best practices for compliance documentation.`;
  }
}
```

Key points:
- Uses `claude-sonnet-4-5` as default model (fast, good quality)
- Non-streaming `createChat()` for simple requests
- Streaming `streamChat()` with abort support
- Token estimation for rate limiting
- Graceful handling when API key not configured
- Tenant isolation via organizationId in params (used by callers)
  </action>
  <verify>
`npm run build` succeeds.
TypeScript types resolve correctly for @anthropic-ai/sdk.
  </verify>
  <done>
AiClientService exports createChat() and streamChat() methods with proper typing.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add environment configuration and test basic connectivity</name>
  <files>
    apps/backend/.env.example
    apps/backend/src/config/configuration.ts
  </files>
  <action>
1. Add to `apps/backend/.env.example`:
```
# AI Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
AI_DEFAULT_MODEL=claude-sonnet-4-5
AI_MAX_TOKENS=4096
```

2. Update `apps/backend/src/config/configuration.ts` to include AI config section:
```typescript
// Add to the configuration object:
ai: {
  anthropicApiKey: process.env.ANTHROPIC_API_KEY,
  defaultModel: process.env.AI_DEFAULT_MODEL || 'claude-sonnet-4-5',
  maxTokens: parseInt(process.env.AI_MAX_TOKENS || '4096', 10),
},
```

3. Create a simple test script in `apps/backend/test-ai.ts` (temporary, can be deleted after verification):
```typescript
import Anthropic from '@anthropic-ai/sdk';

async function testConnection() {
  const apiKey = process.env.ANTHROPIC_API_KEY;
  if (!apiKey) {
    console.log('ANTHROPIC_API_KEY not set - skipping test');
    return;
  }

  const client = new Anthropic({ apiKey });

  try {
    const response = await client.messages.create({
      model: 'claude-sonnet-4-5',
      max_tokens: 100,
      messages: [{ role: 'user', content: 'Say "AI connection test successful" and nothing else.' }],
    });

    console.log('Response:', response.content);
    console.log('Tokens used:', response.usage);
  } catch (error) {
    console.error('Connection test failed:', error.message);
  }
}

testConnection();
```

Run with: `npx ts-node test-ai.ts` (if API key is configured)

After verification, delete test-ai.ts.
  </action>
  <verify>
`npm run build` succeeds.
.env.example contains ANTHROPIC_API_KEY entry.
If ANTHROPIC_API_KEY is set in environment, test script returns response.
  </verify>
  <done>
Environment configuration complete. AI client initializes on module startup with proper logging.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. `npm run build` in apps/backend passes
2. `npm run lint` in apps/backend passes
3. AiModule is imported in app.module.ts
4. @anthropic-ai/sdk is in package.json
5. AiClientService has createChat and streamChat methods
6. TypeScript compiles without errors
</verification>

<success_criteria>
- AiModule created and registered in AppModule
- AiClientService wraps @anthropic-ai/sdk with streaming support
- Service handles missing API key gracefully (logs warning, disables features)
- DTOs defined for chat messages and responses
- Environment configuration documented in .env.example
</success_criteria>

<output>
After completion, create `.planning/phases/05-ai-infrastructure/05-01-SUMMARY.md`
</output>
