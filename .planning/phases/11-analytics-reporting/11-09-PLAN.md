---
phase: 11-analytics-reporting
plan: 09
type: execute
wave: 2
depends_on: ["11-04"]
files_modified:
  - apps/backend/src/modules/analytics/migration/connectors/navex.connector.ts
  - apps/backend/src/modules/analytics/migration/connectors/eqs.connector.ts
  - apps/backend/src/modules/analytics/migration/connectors/csv.connector.ts
  - apps/backend/src/modules/analytics/migration/connectors/base.connector.ts
autonomous: true

must_haves:
  truths:
    - "NAVEX connector can parse EthicsPoint export files"
    - "EQS connector can parse Conversant export files"
    - "Generic CSV connector handles arbitrary CSV with field mapping"
  artifacts:
    - path: "apps/backend/src/modules/analytics/migration/connectors/base.connector.ts"
      provides: "Base connector interface and utilities"
      exports: ["BaseMigrationConnector"]
    - path: "apps/backend/src/modules/analytics/migration/connectors/navex.connector.ts"
      provides: "NAVEX EthicsPoint connector"
      min_lines: 100
  key_links:
    - from: "navex.connector.ts"
      to: "base.connector"
      via: "extends"
      pattern: "extends BaseMigrationConnector"
---

<objective>
Build migration connectors for competitor systems (NAVEX, EQS) and generic CSV.

Purpose: Enable one-time data migration from existing compliance systems (MIG-03, MIG-04, MIG-05).
Output: NAVEX, EQS, and CSV connectors with format detection and field mapping
</objective>

<execution_context>
@C:\Users\cu0718\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\cu0718\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/11-analytics-reporting/11-CONTEXT.md
@.planning/phases/11-analytics-reporting/11-RESEARCH.md
@.planning/phases/11-analytics-reporting/11-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create base connector interface</name>
  <files>apps/backend/src/modules/analytics/migration/connectors/base.connector.ts</files>
  <action>
Create base connector class and interfaces:

```typescript
import csv from 'csv-parser';
import { Readable } from 'stream';

export interface MigrationConnector {
  readonly sourceType: MigrationSourceType;

  // Format detection
  detectFormat(buffer: Buffer): Promise<FormatDetectionResult>;

  // Field mapping
  getAvailableFields(buffer: Buffer): Promise<string[]>;
  getSuggestedMappings(): FieldMapping[];

  // Validation
  validateRow(row: Record<string, string>, mappings: FieldMapping[]): ValidationResult;

  // Transformation
  transformRow(row: Record<string, string>, mappings: FieldMapping[]): TransformedRow;

  // Streaming
  createRowStream(buffer: Buffer): AsyncIterable<Record<string, string>>;
}

export interface FormatDetectionResult {
  isValid: boolean;
  confidence: number;  // 0-1
  detectedType: MigrationSourceType;
  sampleRows: Record<string, unknown>[];
  errors?: string[];
}

export interface FieldMapping {
  sourceField: string;
  targetField: string;
  targetEntity: 'Case' | 'RIU' | 'Person' | 'Investigation';
  isRequired: boolean;
  transform?: FieldTransform;
  defaultValue?: unknown;
}

export type FieldTransform =
  | { type: 'uppercase' }
  | { type: 'lowercase' }
  | { type: 'trim' }
  | { type: 'parseDate'; format: string }
  | { type: 'parseNumber' }
  | { type: 'mapValue'; mappings: Record<string, unknown> }
  | { type: 'concat'; separator: string; fields: string[] }
  | { type: 'split'; separator: string; index: number };

export interface ValidationResult {
  isValid: boolean;
  errors: { field: string; message: string }[];
  warnings: { field: string; message: string }[];
}

export interface TransformedRow {
  case?: Partial<CaseCreateInput>;
  riu?: Partial<RiuCreateInput>;
  person?: Partial<PersonCreateInput>;
  issues: string[];
}

export abstract class BaseMigrationConnector implements MigrationConnector {
  abstract readonly sourceType: MigrationSourceType;
  abstract getSuggestedMappings(): FieldMapping[];

  async detectFormat(buffer: Buffer): Promise<FormatDetectionResult> {
    const content = buffer.toString('utf-8').slice(0, 10000);
    const lines = content.split('\n');

    if (lines.length < 2) {
      return { isValid: false, confidence: 0, detectedType: this.sourceType, sampleRows: [], errors: ['File too short'] };
    }

    const headers = this.parseHeaders(lines[0]);
    const sampleRows = await this.parseSampleRows(buffer, 5);

    const confidence = this.calculateConfidence(headers);

    return {
      isValid: confidence > 0.5,
      confidence,
      detectedType: this.sourceType,
      sampleRows,
    };
  }

  async getAvailableFields(buffer: Buffer): Promise<string[]> {
    const content = buffer.toString('utf-8');
    const firstLine = content.split('\n')[0];
    return this.parseHeaders(firstLine);
  }

  validateRow(row: Record<string, string>, mappings: FieldMapping[]): ValidationResult {
    const errors: { field: string; message: string }[] = [];
    const warnings: { field: string; message: string }[] = [];

    for (const mapping of mappings) {
      const value = row[mapping.sourceField];

      if (mapping.isRequired && (!value || value.trim() === '')) {
        errors.push({ field: mapping.sourceField, message: 'Required field is empty' });
      }

      // Type-specific validation
      if (value && mapping.transform) {
        const validationError = this.validateTransform(value, mapping.transform);
        if (validationError) {
          errors.push({ field: mapping.sourceField, message: validationError });
        }
      }
    }

    return { isValid: errors.length === 0, errors, warnings };
  }

  transformRow(row: Record<string, string>, mappings: FieldMapping[]): TransformedRow {
    const result: TransformedRow = { issues: [] };

    for (const mapping of mappings) {
      let value = row[mapping.sourceField];

      // Apply transform
      if (value && mapping.transform) {
        try {
          value = this.applyTransform(value, mapping.transform, row);
        } catch (error) {
          result.issues.push(`Transform failed for ${mapping.sourceField}: ${error.message}`);
          continue;
        }
      }

      // Use default if empty
      if (!value && mapping.defaultValue !== undefined) {
        value = String(mapping.defaultValue);
      }

      // Set on target entity
      this.setTargetField(result, mapping.targetEntity, mapping.targetField, value);
    }

    return result;
  }

  async *createRowStream(buffer: Buffer): AsyncIterable<Record<string, string>> {
    const stream = Readable.from(buffer);
    const parser = stream.pipe(csv());

    for await (const row of parser) {
      yield row as Record<string, string>;
    }
  }

  protected parseHeaders(line: string): string[] {
    // Handle quoted CSV headers
    const headers: string[] = [];
    let current = '';
    let inQuotes = false;

    for (const char of line) {
      if (char === '"') {
        inQuotes = !inQuotes;
      } else if (char === ',' && !inQuotes) {
        headers.push(current.trim());
        current = '';
      } else {
        current += char;
      }
    }
    headers.push(current.trim());

    return headers;
  }

  protected abstract calculateConfidence(headers: string[]): number;

  protected applyTransform(value: string, transform: FieldTransform, row: Record<string, string>): string {
    switch (transform.type) {
      case 'uppercase': return value.toUpperCase();
      case 'lowercase': return value.toLowerCase();
      case 'trim': return value.trim();
      case 'parseDate': return this.parseDate(value, transform.format);
      case 'parseNumber': return String(parseFloat(value.replace(/[^0-9.-]/g, '')));
      case 'mapValue': return String(transform.mappings[value] ?? value);
      case 'concat': return transform.fields.map(f => row[f] || '').join(transform.separator);
      case 'split': return value.split(transform.separator)[transform.index] || '';
      default: return value;
    }
  }

  private parseDate(value: string, format: string): string {
    // Use date-fns parse with specified format
    const date = parse(value, format, new Date());
    if (isNaN(date.getTime())) throw new Error(`Invalid date: ${value}`);
    return date.toISOString();
  }

  private setTargetField(result: TransformedRow, entity: string, field: string, value: unknown): void {
    if (!result[entity.toLowerCase()]) {
      result[entity.toLowerCase()] = {};
    }
    result[entity.toLowerCase()][field] = value;
  }

  private async parseSampleRows(buffer: Buffer, count: number): Promise<Record<string, unknown>[]> {
    const rows: Record<string, unknown>[] = [];
    for await (const row of this.createRowStream(buffer)) {
      rows.push(row);
      if (rows.length >= count) break;
    }
    return rows;
  }
}
```
  </action>
  <verify>TypeScript compiles without errors</verify>
  <done>BaseMigrationConnector provides common functionality for format detection, validation, and transformation</done>
</task>

<task type="auto">
  <name>Task 2: Implement NAVEX and EQS connectors</name>
  <files>
    apps/backend/src/modules/analytics/migration/connectors/navex.connector.ts
    apps/backend/src/modules/analytics/migration/connectors/eqs.connector.ts
  </files>
  <action>
1. Create NAVEX connector:

```typescript
@Injectable()
export class NavexConnector extends BaseMigrationConnector {
  readonly sourceType = MigrationSourceType.NAVEX;

  // Known NAVEX EthicsPoint column names
  private readonly NAVEX_COLUMNS = [
    'Case Number', 'Case Type', 'Incident Type', 'Case Status',
    'Date Reported', 'Date Closed', 'Reporter Type', 'Anonymous',
    'Location', 'Department', 'Description', 'Resolution',
  ];

  protected calculateConfidence(headers: string[]): number {
    const normalizedHeaders = headers.map(h => h.toLowerCase().trim());
    const matchCount = this.NAVEX_COLUMNS.filter(col =>
      normalizedHeaders.includes(col.toLowerCase())
    ).length;

    return matchCount / this.NAVEX_COLUMNS.length;
  }

  getSuggestedMappings(): FieldMapping[] {
    return [
      {
        sourceField: 'Case Number',
        targetField: 'sourceRecordId',
        targetEntity: 'Case',
        isRequired: true,
      },
      {
        sourceField: 'Case Type',
        targetField: 'categoryName',
        targetEntity: 'Case',
        isRequired: false,
        transform: { type: 'mapValue', mappings: this.getCategoryMappings() },
      },
      {
        sourceField: 'Case Status',
        targetField: 'status',
        targetEntity: 'Case',
        isRequired: true,
        transform: { type: 'mapValue', mappings: {
          'Open': 'OPEN',
          'Closed': 'CLOSED',
          'Pending': 'IN_PROGRESS',
          'Awaiting Response': 'PENDING_RESPONSE',
        }},
      },
      {
        sourceField: 'Date Reported',
        targetField: 'createdAt',
        targetEntity: 'Case',
        isRequired: true,
        transform: { type: 'parseDate', format: 'MM/dd/yyyy' },
      },
      {
        sourceField: 'Date Closed',
        targetField: 'closedAt',
        targetEntity: 'Case',
        isRequired: false,
        transform: { type: 'parseDate', format: 'MM/dd/yyyy' },
      },
      {
        sourceField: 'Anonymous',
        targetField: 'isAnonymous',
        targetEntity: 'RIU',
        isRequired: false,
        transform: { type: 'mapValue', mappings: { 'Yes': 'true', 'No': 'false' }},
      },
      {
        sourceField: 'Description',
        targetField: 'details',
        targetEntity: 'RIU',
        isRequired: true,
        transform: { type: 'trim' },
      },
      // ... additional mappings
    ];
  }

  private getCategoryMappings(): Record<string, string> {
    return {
      'Harassment': 'Harassment',
      'Discrimination': 'Discrimination',
      'Fraud': 'Fraud',
      'Conflict of Interest': 'Conflict of Interest',
      'Ethics Violation': 'Ethics Violation',
      'Safety': 'Safety Concern',
      // Add more based on common NAVEX categories
    };
  }
}
```

2. Create EQS connector:

```typescript
@Injectable()
export class EqsConnector extends BaseMigrationConnector {
  readonly sourceType = MigrationSourceType.EQS;

  // Known EQS/Conversant column names
  private readonly EQS_COLUMNS = [
    'Report ID', 'Report Type', 'Status', 'Created Date',
    'Reporter Type', 'Anonymous Report', 'Location', 'Division',
    'Case Description', 'Investigation Status', 'Outcome',
  ];

  protected calculateConfidence(headers: string[]): number {
    const normalizedHeaders = headers.map(h => h.toLowerCase().trim());
    const matchCount = this.EQS_COLUMNS.filter(col =>
      normalizedHeaders.includes(col.toLowerCase())
    ).length;

    return matchCount / this.EQS_COLUMNS.length;
  }

  getSuggestedMappings(): FieldMapping[] {
    return [
      {
        sourceField: 'Report ID',
        targetField: 'sourceRecordId',
        targetEntity: 'Case',
        isRequired: true,
      },
      {
        sourceField: 'Report Type',
        targetField: 'categoryName',
        targetEntity: 'Case',
        isRequired: false,
      },
      {
        sourceField: 'Status',
        targetField: 'status',
        targetEntity: 'Case',
        isRequired: true,
        transform: { type: 'mapValue', mappings: {
          'New': 'OPEN',
          'In Progress': 'IN_PROGRESS',
          'Completed': 'CLOSED',
          'Closed': 'CLOSED',
        }},
      },
      {
        sourceField: 'Created Date',
        targetField: 'createdAt',
        targetEntity: 'Case',
        isRequired: true,
        transform: { type: 'parseDate', format: 'yyyy-MM-dd' },
      },
      // ... additional EQS-specific mappings
    ];
  }
}
```
  </action>
  <verify>npm run lint passes for both connector files</verify>
  <done>NAVEX and EQS connectors implement format detection and field mapping for their respective systems</done>
</task>

<task type="auto">
  <name>Task 3: Implement generic CSV connector</name>
  <files>apps/backend/src/modules/analytics/migration/connectors/csv.connector.ts</files>
  <action>
Create generic CSV connector with fuzzy field matching:

```typescript
@Injectable()
export class CsvConnector extends BaseMigrationConnector {
  readonly sourceType = MigrationSourceType.GENERIC_CSV;

  // Common field name variations to match
  private readonly FIELD_ALIASES: Record<string, string[]> = {
    caseNumber: ['case_number', 'case_id', 'caseid', 'id', 'report_number', 'incident_id'],
    status: ['status', 'case_status', 'current_status', 'state'],
    category: ['category', 'type', 'case_type', 'incident_type', 'classification'],
    createdAt: ['created', 'created_at', 'date_created', 'date_reported', 'report_date', 'submitted'],
    closedAt: ['closed', 'closed_at', 'date_closed', 'resolution_date', 'completed'],
    description: ['description', 'details', 'narrative', 'summary', 'case_description'],
    isAnonymous: ['anonymous', 'is_anonymous', 'anon', 'reporter_anonymous'],
    location: ['location', 'site', 'facility', 'office'],
    department: ['department', 'business_unit', 'division', 'org_unit'],
    severity: ['severity', 'priority', 'urgency', 'risk_level'],
    outcome: ['outcome', 'resolution', 'finding', 'result'],
  };

  protected calculateConfidence(headers: string[]): number {
    // Generic CSV always returns moderate confidence
    // Higher confidence if we can match common compliance fields
    const normalizedHeaders = headers.map(h => h.toLowerCase().replace(/[^a-z0-9]/g, ''));

    let matchedFields = 0;
    for (const [target, aliases] of Object.entries(this.FIELD_ALIASES)) {
      const normalizedAliases = aliases.map(a => a.toLowerCase().replace(/[^a-z0-9]/g, ''));
      if (normalizedHeaders.some(h => normalizedAliases.includes(h))) {
        matchedFields++;
      }
    }

    // Need at least caseNumber/id and description to be valid
    const hasRequiredFields = normalizedHeaders.some(h =>
      this.FIELD_ALIASES.caseNumber.map(a => a.replace(/[^a-z0-9]/g, '')).includes(h)
    ) && normalizedHeaders.some(h =>
      this.FIELD_ALIASES.description.map(a => a.replace(/[^a-z0-9]/g, '')).includes(h)
    );

    if (!hasRequiredFields) return 0.3;

    return 0.5 + (matchedFields / Object.keys(this.FIELD_ALIASES).length) * 0.4;
  }

  getSuggestedMappings(): FieldMapping[] {
    // Return empty - mappings are dynamically generated based on detected fields
    return [];
  }

  /**
   * Generate suggested mappings based on actual file headers
   */
  async generateMappings(buffer: Buffer): Promise<FieldMapping[]> {
    const headers = await this.getAvailableFields(buffer);
    const mappings: FieldMapping[] = [];

    for (const header of headers) {
      const normalizedHeader = header.toLowerCase().replace(/[^a-z0-9]/g, '');

      for (const [targetField, aliases] of Object.entries(this.FIELD_ALIASES)) {
        const normalizedAliases = aliases.map(a => a.replace(/[^a-z0-9]/g, ''));

        if (normalizedAliases.includes(normalizedHeader)) {
          mappings.push({
            sourceField: header,
            targetField: this.mapToEntityField(targetField),
            targetEntity: this.getTargetEntity(targetField),
            isRequired: targetField === 'caseNumber' || targetField === 'description',
            transform: this.getDefaultTransform(targetField),
          });
          break;
        }
      }
    }

    return mappings;
  }

  /**
   * Calculate string similarity using Levenshtein distance
   */
  private calculateSimilarity(str1: string, str2: string): number {
    const s1 = str1.toLowerCase();
    const s2 = str2.toLowerCase();

    if (s1 === s2) return 1;

    const len1 = s1.length;
    const len2 = s2.length;
    const matrix: number[][] = [];

    for (let i = 0; i <= len1; i++) {
      matrix[i] = [i];
    }
    for (let j = 0; j <= len2; j++) {
      matrix[0][j] = j;
    }

    for (let i = 1; i <= len1; i++) {
      for (let j = 1; j <= len2; j++) {
        const cost = s1[i - 1] === s2[j - 1] ? 0 : 1;
        matrix[i][j] = Math.min(
          matrix[i - 1][j] + 1,
          matrix[i][j - 1] + 1,
          matrix[i - 1][j - 1] + cost,
        );
      }
    }

    const maxLen = Math.max(len1, len2);
    return 1 - matrix[len1][len2] / maxLen;
  }

  private mapToEntityField(field: string): string {
    const fieldMap: Record<string, string> = {
      caseNumber: 'sourceRecordId',
      status: 'status',
      category: 'categoryName',
      createdAt: 'createdAt',
      closedAt: 'closedAt',
      description: 'details',
      isAnonymous: 'isAnonymous',
      location: 'locationName',
      department: 'businessUnitName',
      severity: 'severity',
      outcome: 'outcome',
    };
    return fieldMap[field] || field;
  }

  private getTargetEntity(field: string): 'Case' | 'RIU' | 'Person' {
    const riuFields = ['description', 'isAnonymous'];
    return riuFields.includes(field) ? 'RIU' : 'Case';
  }

  private getDefaultTransform(field: string): FieldTransform | undefined {
    switch (field) {
      case 'createdAt':
      case 'closedAt':
        return { type: 'parseDate', format: 'yyyy-MM-dd' };
      case 'isAnonymous':
        return { type: 'mapValue', mappings: { 'yes': 'true', 'no': 'false', 'true': 'true', 'false': 'false', '1': 'true', '0': 'false' }};
      case 'status':
        return { type: 'uppercase' };
      default:
        return { type: 'trim' };
    }
  }
}
```
  </action>
  <verify>npm run lint && npm run typecheck passes</verify>
  <done>CsvConnector handles generic CSV with fuzzy field matching and dynamic mapping generation</done>
</task>

</tasks>

<verification>
```bash
cd apps/backend
npm run lint -- --fix
npm run typecheck
```
</verification>

<success_criteria>
- BaseMigrationConnector provides format detection and transformation utilities
- NAVEX connector parses EthicsPoint exports with known column mappings
- EQS connector parses Conversant exports with known column mappings
- CSV connector uses fuzzy matching to suggest field mappings
- All connectors support streaming for large files
</success_criteria>

<output>
After completion, create `.planning/phases/11-analytics-reporting/11-09-SUMMARY.md`
</output>
